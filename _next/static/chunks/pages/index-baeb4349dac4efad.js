(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[405],{8312:function(e,t,a){(window.__NEXT_P=window.__NEXT_P||[]).push(["/",function(){return a(3861)}])},3315:function(e,t,a){"use strict";a.r(t);var s=a(5893);a(7294),t.default=e=>{let{news:t}=e;return(0,s.jsx)("div",{className:"w-full bg-[#D9D9D9]/20 max-sm:py-4 py-16",children:(0,s.jsxs)("div",{className:"page-x-width",children:[(0,s.jsx)("h1",{className:"text-2xl font-normal",children:"News"}),(0,s.jsxs)("div",{className:"flex flex-col gap-2",children:[(0,s.jsxs)("div",{className:"grid grid-cols-[auto,1fr] gap-x-8 flex-wrap py-3 border-b border-black/30 text-sm",children:[(0,s.jsx)("div",{children:"24/12/2024"}),(0,s.jsxs)("div",{children:["Introducing ",(0,s.jsx)("a",{href:"https://aguvis-project.github.io/",target:"_blank",className:"underline",children:"Aguvis"})," - A unified vision-based strong agent model for autonomous GUI interaction across web, desktop & mobile platforms."]})]},"top-news"),(0,s.jsxs)("div",{className:"grid grid-cols-[auto,1fr] gap-x-8 flex-wrap py-3 border-b border-black/30 text-sm",children:[(0,s.jsx)("div",{children:"15/12/2024"}),(0,s.jsxs)("div",{children:[(0,s.jsx)("a",{href:"https://huggingface.co/hkunlp/instructor-large",target:"_blank",className:"underline",children:"Instructor embeddings"})," recently hit 5 million downloads on huggingface!"]})]},"top-news"),(0,s.jsxs)("div",{className:"grid grid-cols-[auto,1fr] gap-x-8 flex-wrap py-3 border-b border-black/30 text-sm",children:[(0,s.jsx)("div",{children:"15/11/2024"}),(0,s.jsxs)("div",{children:["6 years after our ",(0,s.jsx)("a",{href:"https://yale-lily.github.io/spider",target:"_blank",className:"underline",children:"Yale Spider 1.0"}),", we're introducing ",(0,s.jsx)("a",{href:"https://spider2-sql.github.io/",target:"_blank",className:"underline",children:"Spider 2.0"}),", the real-world enterprise agentic Text-to-SQL workflow challenge in the LLM era!"]})]},"top-news"),(0,s.jsxs)("div",{className:"grid grid-cols-[auto,1fr] gap-x-8 flex-wrap py-3 border-b border-black/30 text-sm",children:[(0,s.jsx)("div",{children:"23/10/2024"}),(0,s.jsxs)("div",{children:["Excited to see ",(0,s.jsx)("a",{href:"https://www.anthropic.com/news/3-5-models-and-computer-use",target:"_blank",className:"underline",children:"AnthropicAI"})," using our ",(0,s.jsx)("a",{href:"https://os-world.github.io",target:"_blank",className:"underline",children:"OSWorld"})," (NeurIPS'24) to benchmark their computer use!"]})]},"top-news"),(0,s.jsxs)("div",{className:"grid grid-cols-[auto,1fr] gap-x-8 flex-wrap py-3 border-b border-black/30 text-sm",children:[(0,s.jsx)("div",{children:"11/04/2024"}),(0,s.jsxs)("div",{children:["We have released \xa0",(0,s.jsx)("a",{href:"https://os-world.github.io/",target:"_blank",className:"underline",children:"OSWorld"}),",\xa0 A unified, real computer env for multimodal agents to evaluate open-ended computer tasks with arbitrary apps and interfaces on Ubuntu, Windows, & macOS! \xa0"]})]},"top-news"),(0,s.jsxs)("div",{className:"grid grid-cols-[auto,1fr] gap-x-8 flex-wrap py-3 border-b border-black/30 text-sm",children:[(0,s.jsx)("div",{children:"18/10/2023"}),(0,s.jsxs)("div",{children:["We have released \xa0",(0,s.jsx)("a",{href:"https://github.com/xlang-ai/OpenAgents",target:"_blank",className:"underline",children:"\uD83D\uDCA5OpenAgents\uD83D\uDCA5"}),",\xa0 an open platform designed for language agents in the wild! For more details, you can visit our ",(0,s.jsx)("a",{href:"https://arxiv.org/abs/2310.10634",target:"_blank",className:"underline",children:"paper"})," and the ",(0,s.jsx)("a",{href:"https://github.com/xlang-ai/OpenAgents",target:"_blank",className:"underline",children:"code"}),"! \xa0"]})]},"top-news"),(0,s.jsxs)("div",{className:"grid grid-cols-[auto,1fr] gap-x-8 flex-wrap py-3 border-b border-black/30 text-sm",children:[(0,s.jsx)("div",{children:"13/10/2023"}),(0,s.jsxs)("div",{children:["We have released \xa0",(0,s.jsx)("a",{href:"https://github.com/OpenLemur/Lemur",target:"_blank",className:"underline",children:"Lemur70B"}),",\xa0 \uD83D\uDE80 Open & SOTA Foundation Models for Language Agents! The closest open model to GPT-3.5 on \uD83E\uDD1615 agent tasks\uD83E\uDD16! ! Check out our ",(0,s.jsx)("a",{href:"https://arxiv.org/abs/2310.06830",target:"_blank",className:"underline",children:"paper"})," and feel free to download and use the model at \xa0",(0,s.jsx)("a",{href:"https://huggingface.co/OpenLemur",target:"_blank",className:"underline",children:"HuggingFace"}),"!\xa0"]})]},"top-news"),(0,s.jsxs)("div",{className:"grid grid-cols-[auto,1fr] gap-x-8 flex-wrap py-3 border-b border-black/30 text-sm",children:[(0,s.jsx)("div",{children:"28/09/2023"}),(0,s.jsxs)("div",{children:["Introducing ",(0,s.jsx)("a",{href:"https://text-to-reward.github.io/",target:"_blank",className:"underline",children:"Text2Reward"})," - Using LLMs to generate dense reward functions from natural language for robotic RL policy training!"]})]},"top-news")]})]})})}},6328:function(e,t,a){"use strict";a.r(t),a.d(t,{default:function(){return s.default}});var s=a(3315)},6338:function(e,t,a){"use strict";a.r(t),a.d(t,{default:function(){return c}});var s=a(5893);a(7294);var r=a(5675),n=a.n(r),i={src:"/_next/static/media/google.8e5d9b84.svg",height:49,width:70,blurWidth:0,blurHeight:0},l={src:"/_next/static/media/amazon.ab4098f2.svg",height:29,width:82,blurWidth:0,blurHeight:0},d={src:"/_next/static/media/salesforce.f464a0d3.svg",height:1750,width:2500,blurWidth:0,blurHeight:0},o={src:"/_next/static/media/ugc.d399e473.png",height:111,width:688,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAABCAYAAADjAO9DAAAAKUlEQVR4nGPUqy+wZWRh/vptx+GXf+89k2BkZ/3D8P8fEwMDw3cgfgkA6+INdLin03wAAAAASUVORK5CYII=",blurWidth:8,blurHeight:1},c=()=>(0,s.jsx)("div",{className:"w-full bg-[#B9B9B9]/30 h-fit py-6 sm:py-12",children:(0,s.jsxs)("div",{className:"page-x-width",children:[(0,s.jsx)("h1",{className:"max-sm:text-lg max-sm:font-[600] text-2xl mb-4",children:"Acknowledgements"}),(0,s.jsx)("p",{className:"max-sm:text-xs text-sm",children:"We thank the following institutions for their funding support: Google Research, Amazon AWS, Salesforce Research, and UGC."}),(0,s.jsxs)("div",{className:"max-sm:my-8 my-4 w-full flex flex-wrap gap-12 justify-center items-center",children:[(0,s.jsx)(n(),{src:i,alt:"Google Research",width:90,height:90,className:"mt-2"}),(0,s.jsx)(n(),{src:l,alt:"Amazon AWS",width:90,height:90}),(0,s.jsx)(n(),{src:d,alt:"Salesforce Research",width:90,height:90}),(0,s.jsx)(n(),{src:o,alt:"UGC",width:150,height:70})]})]})})},108:function(e,t,a){"use strict";a.r(t),a.d(t,{default:function(){return s.default}});var s=a(6338)},16:function(e,t,a){"use strict";a.r(t);var s=a(5893);a(7294);var r=a(1279),n=a(5675),i=a.n(n);t.default=()=>(0,s.jsx)("div",{className:"w-full max-sm:mt-20 mt-36 max-sm:pb-4 pb-16",children:(0,s.jsxs)("div",{className:"page-x-width",children:[(0,s.jsxs)("h1",{className:"text-2xl mb-6",children:[(0,s.jsx)("b",{children:"XLANG"})," Lab"]}),(0,s.jsxs)("p",{className:"leading-7 mb-8",children:["Welcome to the",(0,s.jsxs)("span",{style:{fontWeight:"bold"},children:[(0,s.jsx)("span",{style:{color:"#643EAD"},children:" Exe"}),"cutable",(0,s.jsx)("span",{style:{color:"#643EAD"},children:" Lang"}),"uage",(0,s.jsx)("span",{style:{color:"#643EAD"},children:" G"}),"rounding (XLANG)"]})," Lab! We are part of the ",(0,s.jsx)("a",{href:"https://nlp.cs.hku.hk/",target:"_blank",className:"underline",children:"HKU NLP Group"})," at the University of Hong Kong. We focus on developing grounded AI agents that empower users to use language to interact with digital and physical environments to carry out real-world tasks. Our systems ground language and perception into code and actions executable in the corresponding environments, including databases (data/coding agent), computers (computer use agent), and the physical world (robotic agent) etc,. Through these agents, we aim to enable non-experts to access complex systems such as databases, software, and robots while unlocking functionalities across existing applications and physical systems that dramatically expand AI capabilities."]}),(0,s.jsx)("div",{className:"col-span-4",children:(0,s.jsx)(i(),{src:(0,r.P)("/demo/teaser.jpg"),alt:"xlang-overview",width:500,height:300,className:"w-full h-auto"})})]})})},6394:function(e,t,a){"use strict";a.r(t),a.d(t,{default:function(){return s.default}});var s=a(16)},3861:function(e,t,a){"use strict";a.r(t),a.d(t,{__N_SSG:function(){return p},default:function(){return f}});var s=a(5893),r=a(9008),n=a.n(r),i=a(6394),l=a(6328),d=a(108),o=a(7294),c=()=>{window.va||(window.va=function(...e){(window.vaq=window.vaq||[]).push(e)})};function u(){return"undefined"!=typeof window}function h(){return"production"}function g(){return"development"===function(){let e=u()?window.vam:h();return e||"production"}()}function x({beforeSend:e,debug:t=!0,mode:a="auto"}){return(0,o.useEffect)(()=>{!function(e={debug:!0}){var t;if(!u())return;(function(e="auto"){if("auto"===e){window.vam=h();return}window.vam=e})(e.mode),c(),e.beforeSend&&(null==(t=window.va)||t.call(window,"beforeSend",e.beforeSend));let a=g()?"https://va.vercel-scripts.com/v1/script.debug.js":"/_vercel/insights/script.js";if(document.head.querySelector(`script[src*="${a}"]`))return;let s=document.createElement("script");s.src=a,s.defer=!0,s.setAttribute("data-sdkn","@vercel/analytics"),s.setAttribute("data-sdkv","1.1.1"),s.onerror=()=>{let e=g()?"Please check if any ad blockers are enabled and try again.":"Be sure to enable Web Analytics for your project and deploy again. See https://vercel.com/docs/analytics/quickstart for more information.";console.log(`[Vercel Web Analytics] Failed to load script from ${a}. ${e}`)},g()&&!1===e.debug&&s.setAttribute("data-debug","false"),document.head.appendChild(s)}({beforeSend:e,debug:t,mode:a})},[e,t,a]),null}var p=!0,f=e=>{let{news:t}=e;return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n(),{children:[(0,s.jsx)("title",{children:"XLANG Lab"}),(0,s.jsx)("link",{rel:"apple-touch-icon",sizes:"180x180",href:"/favicon/white-on-black/apple-touch-icon.png"}),(0,s.jsx)("link",{rel:"icon",type:"image/png",sizes:"32x32",href:"/favicon/white-on-black/favicon-32x32.png"}),(0,s.jsx)("link",{rel:"icon",type:"image/png",sizes:"16x16",href:"/favicon/white-on-black/favicon-16x16.png"}),(0,s.jsx)("link",{rel:"manifest",href:"/favicon/white-on-black/site.webmanifest"})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)(i.default,{}),(0,s.jsx)(l.default,{news:t}),(0,s.jsx)(d.default,{}),(0,s.jsx)(x,{})]})]})}}},function(e){e.O(0,[774,888,179],function(){return e(e.s=8312)}),_N_E=e.O()}]);