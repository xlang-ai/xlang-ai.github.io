<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>XLANG Lab | <!-- -->Introducing XLang: An Open-Source Framework for Building Language Model Agents via Executable Language Grounding</title><link rel="apple-touch-icon" sizes="180x180" href="/favicon/black-on-white/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon/black-on-white/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon/black-on-white/favicon-16x16.png"/><link rel="manifest" href="/favicon/black-on-white/site.webmanifest"/><meta name="description" content="Introducing XLang: An Open-Source Framework for Building Language Model Agents via Executable Language Grounding"/><meta property="og:title" content="Introducing XLang: An Open-Source Framework for Building Language Model Agents via Executable Language Grounding"/><meta property="og:type" content="website"/><meta property="og:image" content="https://i.imgur.com/sPqu2t7.png"/><meta property="og:description" content="Introducing XLang, an open-source platform that constructs language model agents through executable language grounding. Alongside this framework, we unveil demos of XLang Agents, encompassing Data, Plugins, and Web agents. Moving forward, we&#x27;re set to open-source multiple substantial projects, encompassing frameworks, models, demos, code, benchmarks, and beyond."/><meta property="og:url" content="https://xlang.ai/blog/xlang-intro"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Introducing XLang: An Open-Source Framework for Building Language Model Agents via Executable Language Grounding"/><meta name="twitter:description" content="Introducing XLang, an open-source platform that constructs language model agents through executable language grounding. Alongside this framework, we unveil demos of XLang Agents, encompassing Data, Plugins, and Web agents. Moving forward, we&#x27;re set to open-source multiple substantial projects, encompassing frameworks, models, demos, code, benchmarks, and beyond."/><meta name="twitter:image" content="https://i.imgur.com/sPqu2t7.png"/><meta name="next-head-count" content="17"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/c7a1138c526c7fb2.css" as="style"/><link rel="stylesheet" href="/_next/static/css/c7a1138c526c7fb2.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-ee7e63bc15b31913.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-4d525326a36e0ad2.js" defer=""></script><script src="/_next/static/chunks/pages/_app-43f67b4afd5f2ce7.js" defer=""></script><script src="/_next/static/chunks/845-76c3d46a37112c52.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-83a52c83a6b0e812.js" defer=""></script><script src="/_next/static/RdtFddtW1_JW6NpJPDIy4/_buildManifest.js" defer=""></script><script src="/_next/static/RdtFddtW1_JW6NpJPDIy4/_ssgManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;500;600;700&display=swap">@font-face{font-family:'Montserrat';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUHjIg1_i6t8kCHKm4532VJOt5-QNFgpCtr6Ew9.woff) format('woff')}@font-face{font-family:'Montserrat';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUHjIg1_i6t8kCHKm4532VJOt5-QNFgpCtZ6Ew9.woff) format('woff')}@font-face{font-family:'Montserrat';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUHjIg1_i6t8kCHKm4532VJOt5-QNFgpCu170w9.woff) format('woff')}@font-face{font-family:'Montserrat';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUHjIg1_i6t8kCHKm4532VJOt5-QNFgpCuM70w9.woff) format('woff')}@font-face{font-family:'Montserrat';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WRhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Montserrat';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459W1hyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Montserrat';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WZhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Montserrat';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WdhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Montserrat';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WlhyyTh89Y.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Montserrat';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WRhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Montserrat';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459W1hyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Montserrat';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WZhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Montserrat';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WdhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Montserrat';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WlhyyTh89Y.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Montserrat';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WRhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Montserrat';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459W1hyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Montserrat';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WZhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Montserrat';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WdhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Montserrat';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WlhyyTh89Y.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Montserrat';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WRhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Montserrat';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459W1hyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Montserrat';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WZhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Montserrat';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WdhyyTh89ZNpQ.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Montserrat';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/montserrat/v30/JTUSjIg1_i6t8kCHKm459WlhyyTh89Y.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><div class="fixed top-0 left-0 w-full h-14 md:h-20 bg-white py-4 z-10 navbar-shadow"><div class="page-x-width w-full flex justify-between items-center"><div class="sm:hidden w-fit h-fit cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" class="text-[#0156AC]" width="24" height="24" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><line x1="4" y1="6" x2="20" y2="6"></line><line x1="4" y1="12" x2="20" y2="12"></line><line x1="4" y1="18" x2="20" y2="18"></line></svg></div><a href="/"><div class="flex gap-2 items-center cursor-pointer text-brand-dark"><img alt="Xlang" loading="lazy" width="30" height="30" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/icons/logo.svg"/><div>XLANG Lab</div></div></a><ul class="gap-8 text-md text-text-brand-dark hidden sm:flex"><li class="font-[500] hover:underline text-brand-dark"><a href="/">about</a></li><li class="font-[500] hover:underline text-brand-dark"><a href="/team">team</a></li><li class="font-[500] hover:underline text-brand-dark"><a href="/publications">publications</a></li><li class="font-[500] hover:underline text-brand-dark"><a href="/blog">blogs</a></li></ul><div class="flex gap-4 items-center"><ul class="hidden lg:flex gap-3"><li><a href="https://github.com/xlang-ai"><img alt="Xlang" loading="lazy" width="25" height="25" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/icons/github-black.svg"/></a></li><li><a href="https://twitter.com/XLangNLP"><img alt="Xlang" loading="lazy" width="25" height="25" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/icons/twitter-black.svg"/></a></li></ul><div class="max-sm:text-sm border border-brand-primary2 border-2 text-brand-primary2 font-[500] rounded-xl py-1 px-3 cursor-pointer"><a href="https://forms.gle/3Ki9ectMB5D31F8g8" target="_blank" rel="noopener noreferrer">join us</a></div></div></div></div><div class="relative w-full h-full"><div class="absolute top-0 left-0 max-sm:hidden -mt-8 z-[-1]"><img alt="Wave" loading="lazy" width="2000" height="1000" decoding="async" data-nimg="1" style="color:transparent" src="/background/wave.svg"/><img alt="Wave 2" loading="lazy" width="2000" height="1000" decoding="async" data-nimg="1" style="color:transparent" src="/background/wave2.svg"/></div><div class="pt-36 w-full min-h-screen bg-[#D9D9D9]/20"><div class="page-x-width"><div class="flex flex-col gap-8 mb-8"><div class="text-xs text-[#545454] font-[500] tracking-widest"><a href="/blog">Blog</a> / <!-- -->XLANG Intro</div><div class="text-[#0156AC] font-[500] text-3xl text-justify">Introducing XLang: An Open-Source Framework for Building Language Model Agents via Executable Language Grounding</div><div class="flex flex-wrap flex-col w-full"><div class="relative w-full font-[600] text-xs flex flex-wrap grid grid-cols-3 mb-4"><div class="flex flex-col justify-center items-center"><div class="text-[#666666] mb-2">Author</div><div>XLANG Lab</div></div><div class="flex flex-col justify-center items-center"><div class="text-[#666666] mb-2">Date</div><div>Aug 10, 2023</div></div><div class="flex flex-col justify-center items-center"><div class="text-[#666666] mb-2">Share</div><ul class="flex gap-4"><li class="cursor-pointer"><a href="https://join.slack.com/t/xlanggroup/shared_invite/zt-20zb8hxas-eKSGJrbzHiPmrADCDX3_rQ"><img alt="Xlang" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/icons/slack-black.svg"/></a></li><li class="cursor-pointer"><a href="https://github.com/xlang-ai"><img alt="Xlang" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/icons/github-black.svg"/></a></li><li class="cursor-pointer"><a href="https://twitter.com/XLangNLP/status/1689723514134446081"><img alt="Xlang" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/icons/twitter-black.svg"/></a></li></ul></div></div><div class="relative w-full aspect-video rounded-lg"><img alt="Introducing XLang: An Open-Source Framework for Building Language Model Agents via Executable Language Grounding" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:contain;object-position:center top;color:transparent" src="/blog/xlang_overview.png"/></div></div></div><div class="tracking-wide leading-7 mb-24 mt-6"><blockquote>
<p class="mb-4 text-sm leading-7 text-justify"><em>&quot;Many years later, as he faced the firing squad, Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice.&quot; —— One Hundred Years of Solitude, Gabriel Garcia Márquez.</em></p>
</blockquote>
<hr class="my-6"/>
<p class="mb-4 text-sm leading-7 text-justify">When envisioning the future, people have always imagined an intelligent agent capable of following human commands and performing specific tasks, significantly enhancing productivity. In recent times, with the emergence of powerful language models, this vision is accelerating. We&#x27;re getting a fresh perspective on what language model agents can truly achieve. The language model agent represents a crucial step in this burgeoning field, enabling powerful language models to take actions, use tools, execute various tasks and facilitate more intelligent interactions with humans.</p>
<p class="mb-4 text-sm leading-7 text-justify">With great excitement, our team, <strong>XLang Lab</strong>, introduces our recent efforts to exploring and advancing the realm of language model agents. In the upcoming sections, we will elaborate on our mission, workouts, and the outlook for future endeavors. Through our mission, we aspire to humbly provide insightful perspectives on the historical trajectory of this captivating vision, pushing forward the frontiers of what these agents can achieve. With this enthusiasm and determination, let us together embrace a new era of intelligent agents for the future.</p>
<h2 class="text-xl font-[600] my-6 text-justify"><strong>What is XLang?</strong></h2>
<p class="mb-4 text-sm leading-7 text-justify"><strong>Executable Language Grounding (XLang)</strong> refers to the process of converting natural language instructions into <em><strong>code or action sequences executable</strong></em> in some environments. It involves generating code or actions that can interact with the environment, perform specific operations, and produce tangible results. XLang thus serves as a bridge, transforming natural language instructions into code or actions executable within real-world environments. Such environments include but are not limited to databases, web applications, and the physical world navigated by robots.</p>
<blockquote>
<p class="mb-4 text-sm leading-7 text-justify"><em>&quot;Code never lies, comments sometimes do.&quot; —— Ron Jeffries</em></p>
</blockquote>
<p class="mb-4 text-sm leading-7 text-justify">Imagine the process as the transmutation of human instructions and questions — expressed in everyday language — into machine-understandable actions and code. The machine then executes these within a specific environment, leading to changes in the state of that environment. This change is observed, results are analyzed, and a further cycle of interaction with humans is initiated.</p>
<p class="mb-4 text-sm leading-7 text-justify">This process expands the capabilities of the agents <strong>far beyond those of a conventional chatbot</strong>, allowing it to address and serve a much broader scope of tasks and applications. And we believe such process lies at the heart of AI/language agents that interact with various real-world environments via natural language and accomplish tangible tasks for us. Recent advances in Executable Language Grounding incorporate techniques such as LLM (Large Language Models) enhanced with neuro-symbolic tools, code generation or semantic parsing, and dialog or interactive systems.</p>
<p class="mb-4 text-sm leading-7 text-justify">In the current generation of LLMs, we can furnish our models with an assortment of neuro-symbolic tools to enhance their capabilities. Typical inputs to these models could include language from the user, a toolkit brimming with different tools, and a variety of environments. The outcome is an action or code sequence executable within the corresponding environment, often entailing the use of certain tool APIs.</p>
<p class="mb-4 text-sm leading-7 text-justify">The process of building such agents often demands considerable effort and collaboration from a dedicated team. This is where XLang comes into play. Our objective with XLang is to establish an open-source framework and ecosystem for building and evaluating these powerful LLM-powered agents.</p>
<h2 class="text-xl font-[600] my-6 text-justify"><strong>The Motivations and Challenges behind XLang</strong></h2>
<p class="mb-4 text-sm leading-7 text-justify">Our team&#x27;s initial spark of excitement came when OpenAI announced the release of code interpreters and plugins. These tools represented live demonstrations of many years of our research in areas such as code generation, semantic parsing, natural language interfaces, and interactive dialog systems. Unfortunately, we couldn&#x27;t access these tools to experiment with our ideas for improvements. This limitation prompted us to think ambitiously. What if we developed our own open-source code interpreters and plugins, or even a more general agent system and framework? This would not only benefit our team but also other research labs and companies worldwide. By sharing our work, we believe we can contribute to the growth of research and applications in this direction, allowing more people to perform exciting and interesting work on our open-source system. More specifically, by shifting the focus towards interactive and real-time demos, we can:</p>
<ul class="list-disc pl-4 text-sm leading-7 text-justify">
<li>iteratively add and improve the agent’s design and working logics, such as integrating more useful tools</li>
<li>implement robust evaluation procedures for various LLMs (Large Language Models) in a neutral manner; while platforms like Vicuna Arena (chatbots) have served as valuable pioneers in this area, we strive to uncover evaluation metrics tailored specifically for language model agents (chatbots + grounding).</li>
<li>push forward the agentic model’s training and development; by incorporating comprehensive evaluations and continuously iterating the training process, we aim to uncover the shortcomings of LLMs and make iterative improvements.</li>
</ul>
<p class="mb-4 text-sm leading-7 text-justify">In short, by setting the frameworks including a real-time demo, we can further advance the research and development of LLM-powered agents and demonstrate their potential.</p>
<p class="mb-4 text-sm leading-7 text-justify">All such promising directions requires a critical first step: establishing a unified system that real users can access. However, challenges are many. Setting up agent demos is not as straightforward as simply connecting a chatbox to an LLM. It requires considerable effort, both in terms of engineering and research. The agents need to interact with their corresponding environments and effect changes in those environments. The system must robustly handle all sorts of situations, appropriately manage different possible execution results, and present these outcomes in the correct manner. Ensuring the robustness and scalability of this interaction cycle is a significant challenge.</p>
<p class="mb-4 text-sm leading-7 text-justify">Historically, NLP has lacked practical system demonstrations like those found in robotics or databases, and has instead focused more on testing against static benchmarks. However, with the advent of large models, we believe the time has come to bridge this gap. Similar to the MineDojo framework in embodied AI and the ManiSkill for robotics, setting up such an agent framework necessitates long-term cooperation among many individuals. Our goal is to see the fruits of our research move step by step towards real-world applications that will, in the not-so-distant future, be used by millions.</p>
<p class="mb-4 text-sm leading-7 text-justify">Our XLang team of about 15 researchers and developers from various backgrounds including <strong>NLP</strong> (Natural Language Processing), <strong>ML</strong> (Machine Learning), <strong>HCI</strong> (Human Computer Interaction), <strong>VIS</strong> (Visualization), <strong>DB</strong> (Database), <strong>Full-stack</strong> development, <strong>UI design</strong>, and <strong>Robotics</strong> have been working full-time on this project since the end of March. We&#x27;ve invested significant effort in addressing these challenges and minimizing the gap between research and the development of real-world interactive agents. We firmly believe in the value of our work and hope our open-source project will attract more researchers, developers, and designers to contribute to this exciting direction.</p>
<h2 class="text-xl font-[600] my-6 text-justify"><strong>Why Us? Our Journey</strong></h2>
<p class="mb-4 text-sm leading-7 text-justify">The answer to this question is quite straightforward. Our team is deeply interested in this field, and we&#x27;ve always wished for agents that can help people analyze data without coding, and for more natural language-led interaction modes for webs/apps. This was the primary reason why, in March, our team decided within four days of discussing the concept, to congregate in WeWork Shenzhen and commence full-time work on the project. This dedication has continued for more than four months, and we are committed to the long-term development of this project.</p>
<p class="mb-4 text-sm leading-7 text-justify">Many of our team members have been consistently drawn to research problems in this direction. Our team comprises professionals with backgrounds in HCI, DB, NLP, visualization, and ML. We have all conducted extensive work on executable language grounding for building LLM-powered AI agents, specifically natural language interfaces for data in databases and webs/apps.</p>
<p class="mb-4 text-sm leading-7 text-justify">Throughout this process, we have maintained active collaborations with industry players like Salesforce, Microsoft, Amazon, Facebook, Google, especially in the realm of text-to-SQL and code generation. We were also among the pioneers in working with large language models for in-context learning (<a href="https://github.com/HKUNLP/icl-selective-annotation" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>Selective Annotation</strong></a>), LLM + tool use (<a href="https://lm-code-binder.github.io/" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>Binder</strong></a>), instruction tuning and retrieval embeddings for LLM (<a href="https://instructor-embedding.github.io/" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>Instructor Embeddings</strong></a>), code generation and semantic parsing (<a href="https://yale-lily.github.io/spider" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>Spider</strong></a>, <a href="https://ds1000-code-gen.github.io/" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>DS-1000</strong></a>, <a href="https://arxiv.org/abs/2211.16490" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>Coder-Reviewer Reranking</strong></a>, <a href="https://github.com/HKUNLP/UnifiedSKG" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>UnifiedSKG</strong></a>),and interactive dialog systems (<a href="https://github.com/Yushi-Hu/IC-DST" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>ICL-DST</strong></a>, <a href="https://yale-lily.github.io/sparc" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>SParC</strong></a>, <a href="https://yale-lily.github.io/cosql" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>CoSQL</strong></a>, <a href="https://arxiv.org/abs/2209.08834" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>NL2Interface</strong></a>). More about our research can be found on our <a href="https://www.xlang.ai/project" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify">project page</a>.</p>
<p class="mb-4 text-sm leading-7 text-justify">We are a dedicated research team profoundly invested and interested in XLang and language model agents, particularly those related to data and web/app agents. More XLang, code generation, LLM+tool use, and LLM+robotics paper collections can be found in our ACL tutorial on complex reasoning: <a href="https://github.com/xlang-ai/xlang-paper-reading" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify">LLM+tool use</a>.</p>
<h2 class="text-xl font-[600] my-6 text-justify"><strong>XLang Agents: An Introduction</strong></h2>
<p class="mb-4 text-sm leading-7 text-justify">XLang Agents are language model agents developed by our team, aiming to utilize a range of tools to enhance their capabilities, serving as user-centric intelligent agents. Currently the XLang Agents supports three different agents focusing on different application scenarios, including:</p>
<ul class="list-disc pl-4 text-sm leading-7 text-justify">
<li><strong>Data Agent</strong>: This agent is skilled in data tools, allowing efficient data search, manipulation, and visualization. It excels in code execution for data-centric tasks.</li>
<li><strong>Plugins Agent</strong>: With over 200 third-party plugins, this agent addresses diverse daily life needs, aiding in various tasks.</li>
<li><strong>Web Agent</strong>: Utilizing a Chrome extension, this agent automates web navigation, streamlining browsing to find and access information.</li>
<li><strong>Robotic Agent</strong>: comming soon</li>
</ul>
<p class="mb-4 text-sm leading-7 text-justify">💡 We have make all three agents online, just visit 👉<a href="https://chat.xlang.ai" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>XLang Agents</strong></a> and feel free to explore! For more details about XLang Agents, you can also check the official documents in 👉<a href="https://docs.xlang.ai" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify"><strong>XLang Docs</strong></a> !</p>
<p class="mb-4 text-sm leading-7 text-justify"><strong>Here are some interesting things XLang Agents can do!</strong></p>
<hr class="my-6"/>
<h3 class="text-lg font-[600] my-6 text-justify">Data Agent</h3>
<p class="mb-4 text-sm leading-7 text-justify"><strong>Code generation + Data tools = Data Agent!</strong></p>
<p class="mb-4 text-sm leading-7 text-justify">After selecting certain data tools, the agent can take your request and proactively take actions to fulfill your request.</p>
<p class="mb-4 text-sm leading-7 text-justify">In the following example, you will see how data agent help you search a dataset, draw an interactive line plot, and finally construct an ARIMA model to perform some prediction.</p>
<!-- -->
<iframe src="https://www.youtube.com/embed/JabK4PiJJqs" title="Data Agent Overview" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" node="[object Object]" class="w-full aspect-video"></iframe>
<hr class="my-6"/>
<h3 class="text-lg font-[600] my-6 text-justify">Plugins Agent</h3>
<p class="mb-4 text-sm leading-7 text-justify"><strong>Unleash the power of hundreds of real-world applications through our intelligent Plugins system!</strong></p>
<p class="mb-4 text-sm leading-7 text-justify">The Agent uses a provided API YAML to intelligently determines the optimal timing and selection of plugins to invoke. Each plugin has been thoughtfully curated to fulfill various requirements across your everyday life situations.</p>
<p class="mb-4 text-sm leading-7 text-justify">For instance, when traveling to Toronto, it recommends attractions, handles currency conversion, provides weather updates, and suggests clothing, ensuring a hassle-free journey.</p>
<iframe src="https://www.youtube.com/embed/UL7VEAQHYBE" title="Plugins Agent Overview" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" node="[object Object]" class="w-full aspect-video"></iframe>
<hr class="my-6"/>
<h3 class="text-lg font-[600] my-6 text-justify">Web Agent</h3>
<p class="mb-4 text-sm leading-7 text-justify"><strong>Effortlessly navigate the internet with the Web Agent, powering up your browsing experience.</strong></p>
<p class="mb-4 text-sm leading-7 text-justify">The Web Agent, utilizing a Chrome extension, automates website navigation to streamline browsing and enhance information retrieval. It simplifies the user&#x27;s quest for pertinent details and desired resources.</p>
<p class="mb-4 text-sm leading-7 text-justify">Specifically in the following example, the agent extracts movie reviews from IMDb and assists in posting a thread on Twitter. Additionally, our interface facilitates multi-turn interactions, ensuring efficient task completion and enriched user engagement.</p>
<iframe src="https://www.youtube.com/embed/yH31TXBfrKI" title="Web Agent Overview" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" node="[object Object]" class="w-full aspect-video"></iframe>
<hr class="my-6"/>
<p class="mb-4 text-sm leading-7 text-justify">By harnessing the power of large language models in conjunction with diverse tools, XLang Agents significantly expand the capabilities of conversational interfaces, offering intelligent assistance that revolves around the user.</p>
<p class="mb-4 text-sm leading-7 text-justify"><strong>Engage in a conversation with our XLang Agents to explore its wide-ranging capabilities further!</strong></p>
<h2 class="text-xl font-[600] my-6 text-justify"><strong>What&#x27;s Next? The Future</strong></h2>
<p class="mb-4 text-sm leading-7 text-justify">Our aim is to build XLang, an open-source ecosystem and community for building and evaluating language model agents. This release will just be the beginning of our XLang open-source journey. In the following months, and beyond, we will be open-sourcing several significant projects, which will include all frameworks, models, demos, code, benchmarks, and more. We hope that in these particular times in NLP, we can enable more people, rather than just a few large companies or closed start-ups, to participate. We envision these initiatives as the starting point to establish a vivid LLM-powered agents, LLM + tool use, and language grounding community, encouraging more people to contribute, develop and perform exciting research based on our work.</p>
<ul class="list-disc pl-4 text-sm leading-7 text-justify">
<li>Online demos of XLang Agents</li>
<li>Framework or toolkits, more sophisticated LangChain for building and evaluating langauge model agents</li>
<li>Agent demo frontend and backend repos for HCI/VIS + NLP research and developers</li>
<li>Pretraining actionable and agentic large language models (donation supports welcome!)</li>
<li>SOTA methods for code generation, general LLMs, and LLMs + tool use for building language model agents</li>
<li>……</li>
</ul>
<h2 class="text-xl font-[600] my-6 text-justify"><strong>Acknowledgements</strong></h2>
<p class="mb-4 text-sm leading-7 text-justify">We would like to express our gratitude towards Google Research, Amazon AWS, and Salesforce Research. The gift funds and necessary computational resources generously provided by these awards have given us the capability and resources to implement this project. We also appreciate the invaluable advice we received throughout the process.</p>
<p class="mb-4 text-sm leading-7 text-justify"><strong>Personal Acknowledgements by <a href="https://taoyds.github.io/" target="_blank" class="underline cursor-pointer hover:text-brand-primary2 text-justify">Tao</a>:</strong></p>
<p class="mb-4 text-sm leading-7 text-justify">I feel fortunate for the year I spent at UWNLP, which is one of the world&#x27;s top institutions for NLP research. During this time, I observed the nascent shift towards LLM in NLP. I would like to extend my thanks to Noah Smith, Luke Zettlemoyer, and Mari Ostendorf. The idea of XLang came about from a suggestion Luke made during a meeting in his office.</p>
<p class="mb-4 text-sm leading-7 text-justify">I would also like to pay tribute to my late Ph.D. advisor, Dragomir Radev. Without him, it&#x27;s very possible that none of what we are starting today would exist.</p></div></div></div></div><div class="w-full bg-brand-offBlack p-4"><div class="page-x-width flex justify-center sm:justify-between flex-wrap gap-4"><div class="flex gap-2 items-center"><a href="/"><div class="relative"><img alt="Xlang" loading="lazy" width="30" height="30" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/icons/logo-white.svg"/></div></a><div class="text-white text-xs w-fit">© Copyright 2023 XLANG Lab. All right reserved.</div></div><nav><ul class="text-white flex gap-6"><li class="cursor-pointer"><a href="https://discord.com/invite/4Gnw7eTEZR"><img alt="Xlang" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/icons/discord.svg"/></a></li><li class="cursor-pointer"><a href="https://github.com/xlang-ai"><img alt="Xlang" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/icons/github.svg"/></a></li><li class="cursor-pointer"><a href="https://twitter.com/XLangNLP"><img alt="Xlang" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/icons/twitter.svg"/></a></li></ul></nav></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slug":"xlang-intro","content":"\n\n\u003e *\"Many years later, as he faced the firing squad, Colonel Aureliano Buendía was to remember that distant afternoon when his father took him to discover ice.\" —— One Hundred Years of Solitude, Gabriel Garcia Márquez.*\n\u003e\n---\n\nWhen envisioning the future, people have always imagined an intelligent agent capable of following human commands and performing specific tasks, significantly enhancing productivity. In recent times, with the emergence of powerful language models, this vision is accelerating. We're getting a fresh perspective on what language model agents can truly achieve. The language model agent represents a crucial step in this burgeoning field, enabling powerful language models to take actions, use tools, execute various tasks and facilitate more intelligent interactions with humans. \n\nWith great excitement, our team, **XLang Lab**, introduces our recent efforts to exploring and advancing the realm of language model agents. In the upcoming sections, we will elaborate on our mission, workouts, and the outlook for future endeavors. Through our mission, we aspire to humbly provide insightful perspectives on the historical trajectory of this captivating vision, pushing forward the frontiers of what these agents can achieve. With this enthusiasm and determination, let us together embrace a new era of intelligent agents for the future.\n\n## **What is XLang?**\n\n**Executable Language Grounding (XLang)** refers to the process of converting natural language instructions into ***code or action sequences executable*** in some environments. It involves generating code or actions that can interact with the environment, perform specific operations, and produce tangible results. XLang thus serves as a bridge, transforming natural language instructions into code or actions executable within real-world environments. Such environments include but are not limited to databases, web applications, and the physical world navigated by robots.\n\n\u003e *\"Code never lies, comments sometimes do.\" —— Ron Jeffries*\n\u003e\n\nImagine the process as the transmutation of human instructions and questions — expressed in everyday language — into machine-understandable actions and code. The machine then executes these within a specific environment, leading to changes in the state of that environment. This change is observed, results are analyzed, and a further cycle of interaction with humans is initiated.\n\nThis process expands the capabilities of the agents **far beyond those of a conventional chatbot**, allowing it to address and serve a much broader scope of tasks and applications. And we believe such process lies at the heart of AI/language agents that interact with various real-world environments via natural language and accomplish tangible tasks for us. Recent advances in Executable Language Grounding incorporate techniques such as LLM (Large Language Models) enhanced with neuro-symbolic tools, code generation or semantic parsing, and dialog or interactive systems.\n\nIn the current generation of LLMs, we can furnish our models with an assortment of neuro-symbolic tools to enhance their capabilities. Typical inputs to these models could include language from the user, a toolkit brimming with different tools, and a variety of environments. The outcome is an action or code sequence executable within the corresponding environment, often entailing the use of certain tool APIs.\n\nThe process of building such agents often demands considerable effort and collaboration from a dedicated team. This is where XLang comes into play. Our objective with XLang is to establish an open-source framework and ecosystem for building and evaluating these powerful LLM-powered agents.\n\n## **The Motivations and Challenges behind XLang**\n\nOur team's initial spark of excitement came when OpenAI announced the release of code interpreters and plugins. These tools represented live demonstrations of many years of our research in areas such as code generation, semantic parsing, natural language interfaces, and interactive dialog systems. Unfortunately, we couldn't access these tools to experiment with our ideas for improvements. This limitation prompted us to think ambitiously. What if we developed our own open-source code interpreters and plugins, or even a more general agent system and framework? This would not only benefit our team but also other research labs and companies worldwide. By sharing our work, we believe we can contribute to the growth of research and applications in this direction, allowing more people to perform exciting and interesting work on our open-source system. More specifically, by shifting the focus towards interactive and real-time demos, we can:\n\n- iteratively add and improve the agent’s design and working logics, such as integrating more useful tools\n- implement robust evaluation procedures for various LLMs (Large Language Models) in a neutral manner; while platforms like Vicuna Arena (chatbots) have served as valuable pioneers in this area, we strive to uncover evaluation metrics tailored specifically for language model agents (chatbots + grounding).\n- push forward the agentic model’s training and development; by incorporating comprehensive evaluations and continuously iterating the training process, we aim to uncover the shortcomings of LLMs and make iterative improvements.\n\nIn short, by setting the frameworks including a real-time demo, we can further advance the research and development of LLM-powered agents and demonstrate their potential.\n\nAll such promising directions requires a critical first step: establishing a unified system that real users can access. However, challenges are many. Setting up agent demos is not as straightforward as simply connecting a chatbox to an LLM. It requires considerable effort, both in terms of engineering and research. The agents need to interact with their corresponding environments and effect changes in those environments. The system must robustly handle all sorts of situations, appropriately manage different possible execution results, and present these outcomes in the correct manner. Ensuring the robustness and scalability of this interaction cycle is a significant challenge.\n\nHistorically, NLP has lacked practical system demonstrations like those found in robotics or databases, and has instead focused more on testing against static benchmarks. However, with the advent of large models, we believe the time has come to bridge this gap. Similar to the MineDojo framework in embodied AI and the ManiSkill for robotics, setting up such an agent framework necessitates long-term cooperation among many individuals. Our goal is to see the fruits of our research move step by step towards real-world applications that will, in the not-so-distant future, be used by millions.\n\nOur XLang team of about 15 researchers and developers from various backgrounds including **NLP** (Natural Language Processing), **ML** (Machine Learning), **HCI** (Human Computer Interaction), **VIS** (Visualization), **DB** (Database), **Full-stack** development, **UI design**, and **Robotics** have been working full-time on this project since the end of March. We've invested significant effort in addressing these challenges and minimizing the gap between research and the development of real-world interactive agents. We firmly believe in the value of our work and hope our open-source project will attract more researchers, developers, and designers to contribute to this exciting direction.\n\n## **Why Us? Our Journey**\n\nThe answer to this question is quite straightforward. Our team is deeply interested in this field, and we've always wished for agents that can help people analyze data without coding, and for more natural language-led interaction modes for webs/apps. This was the primary reason why, in March, our team decided within four days of discussing the concept, to congregate in WeWork Shenzhen and commence full-time work on the project. This dedication has continued for more than four months, and we are committed to the long-term development of this project.\n\nMany of our team members have been consistently drawn to research problems in this direction. Our team comprises professionals with backgrounds in HCI, DB, NLP, visualization, and ML. We have all conducted extensive work on executable language grounding for building LLM-powered AI agents, specifically natural language interfaces for data in databases and webs/apps. \n\nThroughout this process, we have maintained active collaborations with industry players like Salesforce, Microsoft, Amazon, Facebook, Google, especially in the realm of text-to-SQL and code generation. We were also among the pioneers in working with large language models for in-context learning ([**Selective Annotation**](https://github.com/HKUNLP/icl-selective-annotation)), LLM + tool use ([**Binder**](https://lm-code-binder.github.io/)), instruction tuning and retrieval embeddings for LLM ([**Instructor Embeddings**](https://instructor-embedding.github.io/)), code generation and semantic parsing ([**Spider**](https://yale-lily.github.io/spider), [**DS-1000**](https://ds1000-code-gen.github.io/), [**Coder-Reviewer Reranking**](https://arxiv.org/abs/2211.16490), [**UnifiedSKG**](https://github.com/HKUNLP/UnifiedSKG)),and interactive dialog systems ([**ICL-DST**](https://github.com/Yushi-Hu/IC-DST), [**SParC**](https://yale-lily.github.io/sparc), [**CoSQL**](https://yale-lily.github.io/cosql), [**NL2Interface**](https://arxiv.org/abs/2209.08834)). More about our research can be found on our [project page](https://www.xlang.ai/project). \n\nWe are a dedicated research team profoundly invested and interested in XLang and language model agents, particularly those related to data and web/app agents. More XLang, code generation, LLM+tool use, and LLM+robotics paper collections can be found in our ACL tutorial on complex reasoning: [LLM+tool use](https://github.com/xlang-ai/xlang-paper-reading).\n\n## **XLang Agents: An Introduction**\n\nXLang Agents are language model agents developed by our team, aiming to utilize a range of tools to enhance their capabilities, serving as user-centric intelligent agents. Currently the XLang Agents supports three different agents focusing on different application scenarios, including:\n\n- **Data Agent**: This agent is skilled in data tools, allowing efficient data search, manipulation, and visualization. It excels in code execution for data-centric tasks.\n- **Plugins Agent**: With over 200 third-party plugins, this agent addresses diverse daily life needs, aiding in various tasks.\n- **Web Agent**: Utilizing a Chrome extension, this agent automates web navigation, streamlining browsing to find and access information.\n- **Robotic Agent**: comming soon\n    \n💡 We have make all three agents online, just visit 👉[**XLang Agents**](https://chat.xlang.ai) and feel free to explore! For more details about XLang Agents, you can also check the official documents in 👉[**XLang Docs**](https://docs.xlang.ai) !\n\n**Here are some interesting things XLang Agents can do!**\n\n---\n\n### Data Agent\n\n**Code generation + Data tools = Data Agent!**\n\nAfter selecting certain data tools, the agent can take your request and proactively take actions to fulfill your request. \n\nIn the following example, you will see how data agent help you search a dataset, draw an interactive line plot, and finally construct an ARIMA model to perform some prediction.\n\n\u003c!-- [https://www.youtube.com/watch?v=JabK4PiJJqs](https://www.youtube.com/watch?v=JabK4PiJJqs) --\u003e\n\u003ciframe src=\"https://www.youtube.com/embed/JabK4PiJJqs\" title=\"Data Agent Overview\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen\u003e\u003c/iframe\u003e\n\n---\n\n### Plugins Agent\n\n**Unleash the power of hundreds of real-world applications through our intelligent Plugins system!**\n\nThe Agent uses a provided API YAML to intelligently determines the optimal timing and selection of plugins to invoke. Each plugin has been thoughtfully curated to fulfill various requirements across your everyday life situations.\n\nFor instance, when traveling to Toronto, it recommends attractions, handles currency conversion, provides weather updates, and suggests clothing, ensuring a hassle-free journey.\n\n\u003ciframe src=\"https://www.youtube.com/embed/UL7VEAQHYBE\" title=\"Plugins Agent Overview\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen\u003e\u003c/iframe\u003e\n\n---\n\n### Web Agent\n\n**Effortlessly navigate the internet with the Web Agent, powering up your browsing experience.**\n\nThe Web Agent, utilizing a Chrome extension, automates website navigation to streamline browsing and enhance information retrieval. It simplifies the user's quest for pertinent details and desired resources. \n\nSpecifically in the following example, the agent extracts movie reviews from IMDb and assists in posting a thread on Twitter. Additionally, our interface facilitates multi-turn interactions, ensuring efficient task completion and enriched user engagement.\n\n\u003ciframe src=\"https://www.youtube.com/embed/yH31TXBfrKI\" title=\"Web Agent Overview\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen\u003e\u003c/iframe\u003e\n\n---\n\nBy harnessing the power of large language models in conjunction with diverse tools, XLang Agents significantly expand the capabilities of conversational interfaces, offering intelligent assistance that revolves around the user. \n\n**Engage in a conversation with our XLang Agents to explore its wide-ranging capabilities further!**\n\n## **What's Next? The Future**\n\nOur aim is to build XLang, an open-source ecosystem and community for building and evaluating language model agents. This release will just be the beginning of our XLang open-source journey. In the following months, and beyond, we will be open-sourcing several significant projects, which will include all frameworks, models, demos, code, benchmarks, and more. We hope that in these particular times in NLP, we can enable more people, rather than just a few large companies or closed start-ups, to participate. We envision these initiatives as the starting point to establish a vivid LLM-powered agents, LLM + tool use, and language grounding community, encouraging more people to contribute, develop and perform exciting research based on our work.\n\n- Online demos of XLang Agents\n- Framework or toolkits, more sophisticated LangChain for building and evaluating langauge model agents\n- Agent demo frontend and backend repos for HCI/VIS + NLP research and developers\n- Pretraining actionable and agentic large language models (donation supports welcome!)\n- SOTA methods for code generation, general LLMs, and LLMs + tool use for building language model agents\n- ……\n\n## **Acknowledgements**\n\nWe would like to express our gratitude towards Google Research, Amazon AWS, and Salesforce Research. The gift funds and necessary computational resources generously provided by these awards have given us the capability and resources to implement this project. We also appreciate the invaluable advice we received throughout the process.\n\n**Personal Acknowledgements by [Tao](https://taoyds.github.io/):**\n\nI feel fortunate for the year I spent at UWNLP, which is one of the world's top institutions for NLP research. During this time, I observed the nascent shift towards LLM in NLP. I would like to extend my thanks to Noah Smith, Luke Zettlemoyer, and Mari Ostendorf. The idea of XLang came about from a suggestion Luke made during a meeting in his office.\n\nI would also like to pay tribute to my late Ph.D. advisor, Dragomir Radev. Without him, it's very possible that none of what we are starting today would exist.\n","title":"Introducing XLang: An Open-Source Framework for Building Language Model Agents via Executable Language Grounding","shortTitle":"XLANG Intro","date":"10 August 2023","author":"XLANG Lab","coverImage":"/blog/xlang_overview.png","previewContent":"Introducing XLang, an open-source platform that constructs language model agents through executable language grounding. Alongside this framework, we unveil demos of XLang Agents, encompassing Data, Plugins, and Web agents. Moving forward, we're set to open-source multiple substantial projects, encompassing frameworks, models, demos, code, benchmarks, and beyond.","onlineImage":"https://i.imgur.com/sPqu2t7.png","twitterLink":"https://twitter.com/XLangNLP/status/1689723514134446081"}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"xlang-intro"},"buildId":"RdtFddtW1_JW6NpJPDIy4","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>